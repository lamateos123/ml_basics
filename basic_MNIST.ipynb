{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n",
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/watson/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82ad5b30cfe4ac5a61dfd155a1b1a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /home/watson/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# MNIST basic \n",
    "# NN version\n",
    "# CNN version\n",
    "#\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "print(tf.__version__)\n",
    "\n",
    "# load data\n",
    "(ds_train, ds_test), ds_info = tfds.load('mnist',\n",
    "                                         split=['train', 'test'],\n",
    "                                         shuffle_files=True,\n",
    "                                         as_supervised=True,\n",
    "                                         with_info=True,\n",
    "                                        )\n",
    "\n",
    "# normalize image data\n",
    "def normalize_img(image, label):\n",
    "    #Normalizes images: uint8 -> float32\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 28, 28, 1) tf.Tensor(\n",
      "[3 0 3 5 3 6 3 6 1 6 2 7 6 5 4 8 8 3 4 6 7 9 4 5 4 1 2 3 5 6 0 5 3 2 5 5 5\n",
      " 8 8 9 9 6 0 8 2 2 4 9 7 8 2 5 2 3 7 6 8 7 2 3 7 5 4 1 1 1 5 5 8 0 9 5 0 3\n",
      " 3 4 0 1 4 2 6 9 6 9 9 2 2 0 4 3 6 1 8 1 9 5 1 0 9 4 8 6 6 9 9 8 3 1 4 2 0\n",
      " 2 4 6 9 1 8 5 0 1 1 3 2 7 7 5 0 3], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Visualize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ds = ds_train.take(1)\n",
    "\n",
    "for image, label in ds:\n",
    "    print(image.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_5caf7dea_f8ef_11ec_a2d1_44850056e456\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >image</th>        <th class=\"col_heading level0 col1\" >label</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_5caf7dea_f8ef_11ec_a2d1_44850056e456level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_5caf7dea_f8ef_11ec_a2d1_44850056e456row0_col0\" class=\"data row0 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzElEQVR4nGNgGPQg5F8qjMmEIRn1XwinRvnvp2QxdTIyMjAwMDDksd17jCnpeN6CgYGBQZfhAhbzLP+WMzAwyPz8IAkXQuh8ycDAwMAQyHr1ORZJYQYGBgYGKYYDDFgkAxgZGBikMxnnISQZYQz2J0KXjwvpqV00+YfpnsS/f//++/v3bxiSGAuMYfp97rN3b1cz7MDiEQgI+bcGmYsatlH/T+PUyPD2jwVOOaOP23Br3P3vZyZOO///v7qGARd4/EkBt7FvbuOWoyIAAPBxN9oBRuu9AAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
       "                        <td id=\"T_5caf7dea_f8ef_11ec_a2d1_44850056e456row0_col1\" class=\"data row0 col1\" >4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5caf7dea_f8ef_11ec_a2d1_44850056e456level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_5caf7dea_f8ef_11ec_a2d1_44850056e456row1_col0\" class=\"data row1 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmklEQVR4nGNgGOyAc/5KJlxyjIv+/TPEJan9798HWRgH3YhQBoZHj3HpfP/vVxQuOYF//54ieGjGNjEwXMalkeHbv3+eeCTfseAy1oCVYeofXBp3/f8lgUtO/su/azhtnPLvXwJOycv//uGU0//5bx1OySP//hngkuN5+u8tG4oIkj/VJBmO/8Il6cvAMBunlSIvX3DjlKQmAACHtTHZmy2LVAAAAABJRU5ErkJggg==\" alt=\"Img\" /></td>\n",
       "                        <td id=\"T_5caf7dea_f8ef_11ec_a2d1_44850056e456row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5caf7dea_f8ef_11ec_a2d1_44850056e456level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_5caf7dea_f8ef_11ec_a2d1_44850056e456row2_col0\" class=\"data row2 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+0lEQVR4nM3QvyuEARzH8feVniSFiTBcKf8A85ESNqwkdbeY5NdmY/UXiM0z+Ad0SXZ1g0vJjw0Xi86pc13eD8NleJ47q3zG76tv3x/wJxk+jQ7bf8NldT9obdNl1fWW1nGh6mtLPIm0oJVWlvuIvOvMWx1qtqWa0U2aULNNNnCtT+MQapi0waK6CoR6mcS8Wuhq4Fqj1PZjU5NQnX0DUine433dD1qZBwjOrM/EsVc9AmCj6c5MWT8XADjX2mgMi+otABN1k0/YVncAFu/VLWLbPgNBduRxLBMQHe/FZ+Zs5EtLm8kP9F81MHrZTScNelZK6sFcXzP9o3wDadaKxdoXqEQAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
       "                        <td id=\"T_5caf7dea_f8ef_11ec_a2d1_44850056e456row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5caf7dea_f8ef_11ec_a2d1_44850056e456level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_5caf7dea_f8ef_11ec_a2d1_44850056e456row3_col0\" class=\"data row3 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA40lEQVR4nGNgGJpg//8OdCEWKM2obvgv/++6/zcZnJQebPuNqkjvLxI4IIgiJ3/v79/3b//9/fvv7993f/9NQzE2TZ6hc8J3JwYGBgaGK7cYeJE12n79+1cCxlH9+/cVB5LOlxy/pryHSUYyMO78gSR5W/vzU7gxfAz/cfq36fvfDw445Fr+/P3bg12KMebb37+7WbDKKSz89/fvNRmscjpb//79u0YBq5z0yb9//2bhcEvXv78fs1ixyzX//PsuHYc+gbvwAMcEmX//3kFzJxOc9YCRoesJLp3sx9+p4JIjGQAAnrpmBs0pxioAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
       "                        <td id=\"T_5caf7dea_f8ef_11ec_a2d1_44850056e456row3_col1\" class=\"data row3 col1\" >7</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      4\n",
       "1  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      1\n",
       "2  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      0\n",
       "3  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds, info = tfds.load('mnist', split='train', with_info=True)\n",
    "\n",
    "tfds.as_dataframe(ds.take(4), info)\n",
    "#fig = tfds.show_examples(ds, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "{'image': (28, 28, 1), 'label': ()}\n",
      "{'image': tf.uint8, 'label': tf.int64}\n",
      "(28, 28, 1)\n",
      "<dtype: 'uint8'>\n"
     ]
    }
   ],
   "source": [
    "print(info.features[\"label\"].num_classes)\n",
    "print(info.features[\"label\"].names)\n",
    "print(info.features.shape)\n",
    "print(info.features.dtype)\n",
    "print(info.features['image'].shape)\n",
    "print(info.features['image'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': <SplitInfo num_examples=10000, num_shards=1>, 'train': <SplitInfo num_examples=60000, num_shards=1>}\n",
      "['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "print(info.splits)\n",
    "print(list(info.splits.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "['mnist-train.tfrecord-00000-of-00001']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(info.splits['train'].num_examples)\n",
    "print(info.splits['train'].filenames)\n",
    "print(info.splits['train'].num_shards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000\n",
      "[FileInstruction(filename='mnist-train.tfrecord-00000-of-00001', skip=9000, take=36000, num_examples=36000)]\n"
     ]
    }
   ],
   "source": [
    "print(info.splits['train[15%:75%]'].num_examples)\n",
    "print(info.splits['train[15%:75%]'].file_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model NN\n",
    "modelNN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# model NN compile\n",
    "modelNN.compile(\n",
    "    optimizer=tf.keras.optimizer.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]),\n",
    "\n",
    "# model NN fit\n",
    "model.fit(ds_train,\n",
    "         epochs=6,\n",
    "         validation_data=ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model CNN\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
